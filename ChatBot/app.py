from langchain_community.vectorstores import Chroma
from sentence_transformers import SentenceTransformer
from pydantic import BaseModel
from fastapi import FastAPI

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
DATA_DIR = "data"
DB_DIR = "chroma_db_nomic"

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Nomic
nomic_model = SentenceTransformer(
    "nomic-ai/nomic-embed-text-v1.5", 
    trust_remote_code=True
)

# ÙƒÙ„Ø§Ø³ Ù„ØªØºÙ„ÙŠÙ Ø§Ù„Ù€ embeddings
class NomicEmbeddings:
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        return self.model.encode(texts).tolist()

    def embed_query(self, text):
        return self.model.encode([text])[0].tolist()

embedding_model = NomicEmbeddings(nomic_model)

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Chroma
print("ğŸ“‚ Loading existing Chroma DB...")
db = Chroma(
    persist_directory=DB_DIR,
    embedding_function=embedding_model
)

# Ø¥Ø¹Ø¯Ø§Ø¯ FastAPI
app = FastAPI(title="Legal Chatbot API", description="Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Chroma + Nomic embeddings")

# ØªØ¹Ø±ÙŠÙ Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
class QueryRequest(BaseModel):
    question: str
    k: int = 1

@app.post("/ask")
def ask(request: QueryRequest):
    results = db.similarity_search(request.question, k=request.k)
    if results:  
        answer = results[0].page_content   # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© ÙÙ‚Ø·
    else:
        answer = "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬."
    return {
        "query": request.question,
        "answer": answer
    }
